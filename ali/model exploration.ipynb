{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "base_module_path = os.path.abspath(os.path.join('..'))\n",
    "if base_module_path not in sys.path:\n",
    "    sys.path.append(base_module_path)\n",
    "import ama as a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vgg = a.vgg.Vgg\n",
    "preprocess = a.preprocess\n",
    "TrainBatch = a.trainbatch.TrainBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path= '../data/'\n",
    "batch_size = 128\n",
    "img_size = (64,64)\n",
    "#class_weights = [189, 3.2, 1.7, 2.3, 4.8, 463, 34, 1, 80, 59, 25, 66, 560, 155, 1, 2.2, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg(input_shape=(3,)+img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34479 images belonging to 1 classes.\n",
      "Found 6000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "traingen = TrainBatch(path+'train-jpg/', path+'train_v2.csv', batch_size=batch_size, img_size=img_size)\n",
    "valgen = TrainBatch(path+'val-jpg/', path+'train_v2.csv', batch_size=batch_size, img_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "34479/34479 [==============================] - 414s - loss: 0.2919 - acc: 0.8894 - val_loss: 0.2051 - val_acc: 0.9294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6b3394f90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg.model.fit_generator(traingen, samples_per_epoch=traingen.nb_sample, nb_epoch=1,\n",
    "                        validation_data=valgen, nb_val_samples=valgen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "34479/34479 [==============================] - 184s - loss: 0.1686 - acc: 0.9329 - val_loss: 0.1912 - val_acc: 0.9299\n",
      "Epoch 2/5\n",
      "34479/34479 [==============================] - 184s - loss: 0.1525 - acc: 0.9396 - val_loss: 0.1456 - val_acc: 0.9407\n",
      "Epoch 3/5\n",
      "34479/34479 [==============================] - 184s - loss: 0.1405 - acc: 0.9433 - val_loss: 0.1421 - val_acc: 0.9432\n",
      "Epoch 4/5\n",
      "34479/34479 [==============================] - 184s - loss: 0.1321 - acc: 0.9466 - val_loss: 0.1312 - val_acc: 0.9473\n",
      "Epoch 5/5\n",
      "34479/34479 [==============================] - 184s - loss: 0.1251 - acc: 0.9495 - val_loss: 0.1238 - val_acc: 0.9505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6cd9e7fd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg.model.fit_generator(traingen, samples_per_epoch=traingen.nb_sample, nb_epoch=5,\n",
    "                        validation_data=valgen, nb_val_samples=valgen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "34479/34479 [==============================] - 184s - loss: 0.1222 - acc: 0.9511 - val_loss: 0.1215 - val_acc: 0.9520\n",
      "Epoch 2/14\n",
      "34479/34479 [==============================] - 184s - loss: 0.1166 - acc: 0.9531 - val_loss: 0.1212 - val_acc: 0.9520\n",
      "Epoch 3/14\n",
      "34479/34479 [==============================] - 184s - loss: 0.1110 - acc: 0.9553 - val_loss: 0.1176 - val_acc: 0.9536\n",
      "Epoch 4/14\n",
      "34479/34479 [==============================] - 184s - loss: 0.1053 - acc: 0.9576 - val_loss: 0.1203 - val_acc: 0.9523\n",
      "Epoch 5/14\n",
      "34479/34479 [==============================] - 184s - loss: 0.1058 - acc: 0.9576 - val_loss: 0.1990 - val_acc: 0.9218\n",
      "Epoch 6/14\n",
      "34479/34479 [==============================] - 184s - loss: 0.1051 - acc: 0.9575 - val_loss: 0.1241 - val_acc: 0.9521\n",
      "Epoch 7/14\n",
      "34479/34479 [==============================] - 184s - loss: 0.0906 - acc: 0.9636 - val_loss: 0.1222 - val_acc: 0.9535\n",
      "Epoch 8/14\n",
      "34479/34479 [==============================] - 184s - loss: 0.0812 - acc: 0.9671 - val_loss: 0.1319 - val_acc: 0.9504\n",
      "Epoch 9/14\n",
      "34479/34479 [==============================] - 185s - loss: 0.0835 - acc: 0.9667 - val_loss: 0.1427 - val_acc: 0.9496\n",
      "Epoch 10/14\n",
      "34479/34479 [==============================] - 183s - loss: 0.0706 - acc: 0.9717 - val_loss: 0.1600 - val_acc: 0.9476\n",
      "Epoch 11/14\n",
      "10496/34479 [========>.....................] - ETA: 117s - loss: 0.0695 - acc: 0.9721"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-85ee6874682a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m vgg.model.fit_generator(traingen, samples_per_epoch=traingen.nb_sample, nb_epoch=14,\n\u001b[0;32m----> 3\u001b[0;31m                         validation_data=valgen, nb_val_samples=valgen.nb_sample)\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1442\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1444\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg.model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg.model.fit_generator(traingen, samples_per_epoch=traingen.nb_sample, nb_epoch=14,\n",
    "                        validation_data=valgen, nb_val_samples=valgen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from ama.persistenthistory import PersistentHistory\n",
    "\n",
    "filepath = '../data/weights/conv_best.hk'\n",
    "saver = ModelCheckpoint(filepath, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "history = PersistentHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "34351/34479 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9780Epoch 00000: val_loss improved from inf to 0.14217, saving model to ../data/weights/conv_best.hk\n",
      "34479/34479 [==============================] - 183s - loss: 0.0554 - acc: 0.9780 - val_loss: 0.1422 - val_acc: 0.9532\n",
      "Epoch 2/5\n",
      "34351/34479 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9799Epoch 00001: val_loss did not improve\n",
      "34479/34479 [==============================] - 183s - loss: 0.0513 - acc: 0.9799 - val_loss: 0.1444 - val_acc: 0.9532\n",
      "Epoch 3/5\n",
      "34351/34479 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9811Epoch 00002: val_loss did not improve\n",
      "34479/34479 [==============================] - 183s - loss: 0.0485 - acc: 0.9811 - val_loss: 0.1462 - val_acc: 0.9533\n",
      "Epoch 4/5\n",
      "34351/34479 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9819Epoch 00003: val_loss did not improve\n",
      "34479/34479 [==============================] - 184s - loss: 0.0470 - acc: 0.9819 - val_loss: 0.1479 - val_acc: 0.9531\n",
      "Epoch 5/5\n",
      "34351/34479 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9831Epoch 00004: val_loss did not improve\n",
      "34479/34479 [==============================] - 184s - loss: 0.0438 - acc: 0.9831 - val_loss: 0.1494 - val_acc: 0.9528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6a9833890>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.model.compile(optimizer=Adam(lr=0.0001),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg.model.fit_generator(traingen, samples_per_epoch=traingen.nb_sample, nb_epoch=5,\n",
    "                        validation_data=valgen, nb_val_samples=valgen.nb_sample,\n",
    "                        callbacks=[history, saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ama.trainbatch import TrainBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34479 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "gen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
    "       height_shift_range=0.1, shear_range=0.15, zoom_range=0.1,\n",
    "        horizontal_flip=True, fill_mode='wrap')\n",
    "traingen = TrainBatch(path+'train-jpg/', path+'train_v2.csv', batch_size=batch_size, img_size=img_size,\n",
    "                      imagegen=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9503Epoch 00000: val_loss did not improve\n",
      "34479/34479 [==============================] - 184s - loss: 0.1349 - acc: 0.9503 - val_loss: 0.1430 - val_acc: 0.9450\n",
      "Epoch 2/5\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.1191 - acc: 0.9538Epoch 00001: val_loss improved from 0.14217 to 0.11210, saving model to ../data/weights/conv_best.hk\n",
      "34479/34479 [==============================] - 197s - loss: 0.1190 - acc: 0.9538 - val_loss: 0.1121 - val_acc: 0.9563\n",
      "Epoch 3/5\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9561Epoch 00002: val_loss improved from 0.11210 to 0.11017, saving model to ../data/weights/conv_best.hk\n",
      "34479/34479 [==============================] - 195s - loss: 0.1130 - acc: 0.9561 - val_loss: 0.1102 - val_acc: 0.9571\n",
      "Epoch 4/5\n",
      "22400/34479 [==================>...........] - ETA: 59s - loss: 0.1117 - acc: 0.9563"
     ]
    }
   ],
   "source": [
    "vgg.model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg.model.fit_generator(traingen, samples_per_epoch=traingen.nb_sample, nb_epoch=5,\n",
    "                        validation_data=valgen, nb_val_samples=valgen.nb_sample,\n",
    "                        callbacks=[history, saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights('../data/weights/conv_best.hk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9573Epoch 00000: val_loss improved from inf to 0.10628, saving model to ../data/weights/conv_best.hk\n",
      "34479/34479 [==============================] - 193s - loss: 0.1091 - acc: 0.9573 - val_loss: 0.1063 - val_acc: 0.9582\n",
      "Epoch 2/10\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9581Epoch 00001: val_loss improved from 0.10628 to 0.10589, saving model to ../data/weights/conv_best.hk\n",
      "34479/34479 [==============================] - 194s - loss: 0.1074 - acc: 0.9581 - val_loss: 0.1059 - val_acc: 0.9586\n",
      "Epoch 3/10\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9586Epoch 00002: val_loss did not improve\n",
      "34479/34479 [==============================] - 184s - loss: 0.1056 - acc: 0.9586 - val_loss: 0.1070 - val_acc: 0.9587\n",
      "Epoch 4/10\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9590Epoch 00003: val_loss improved from 0.10589 to 0.10545, saving model to ../data/weights/conv_best.hk\n",
      "34479/34479 [==============================] - 191s - loss: 0.1049 - acc: 0.9590 - val_loss: 0.1054 - val_acc: 0.9585\n",
      "Epoch 5/10\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9568Epoch 00006: val_loss did not improve\n",
      "34479/34479 [==============================] - 184s - loss: 0.1099 - acc: 0.9568 - val_loss: 0.1138 - val_acc: 0.9557\n",
      "Epoch 8/10\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9591Epoch 00007: val_loss did not improve\n",
      "34479/34479 [==============================] - 184s - loss: 0.1052 - acc: 0.9591 - val_loss: 0.1042 - val_acc: 0.9600\n",
      "Epoch 9/10\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9603Epoch 00008: val_loss improved from 0.10372 to 0.10240, saving model to ../data/weights/conv_best.hk\n",
      "34479/34479 [==============================] - 190s - loss: 0.1014 - acc: 0.9603 - val_loss: 0.1024 - val_acc: 0.9604\n",
      "Epoch 10/10\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9606Epoch 00009: val_loss did not improve\n",
      "34479/34479 [==============================] - 184s - loss: 0.1006 - acc: 0.9606 - val_loss: 0.1025 - val_acc: 0.9603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fecc8443190>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg.model.fit_generator(traingen, samples_per_epoch=traingen.nb_sample, nb_epoch=10,\n",
    "                        validation_data=valgen, nb_val_samples=valgen.nb_sample,\n",
    "                        callbacks=[history, saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9622Epoch 00000: val_loss improved from inf to 0.09829, saving model to ../data/weights/conv_best.hk\n",
      "34479/34479 [==============================] - 190s - loss: 0.0963 - acc: 0.9622 - val_loss: 0.0983 - val_acc: 0.9612\n",
      "Epoch 2/5\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9625Epoch 00001: val_loss improved from 0.09829 to 0.09784, saving model to ../data/weights/conv_best.hk\n",
      "34479/34479 [==============================] - 188s - loss: 0.0957 - acc: 0.9625 - val_loss: 0.0978 - val_acc: 0.9617\n",
      "Epoch 3/5\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9628Epoch 00002: val_loss did not improve\n",
      "34479/34479 [==============================] - 184s - loss: 0.0950 - acc: 0.9628 - val_loss: 0.0979 - val_acc: 0.9610\n",
      "Epoch 4/5\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9630Epoch 00003: val_loss improved from 0.09784 to 0.09737, saving model to ../data/weights/conv_best.hk\n",
      "34479/34479 [==============================] - 189s - loss: 0.0945 - acc: 0.9630 - val_loss: 0.0974 - val_acc: 0.9616\n",
      "Epoch 5/5\n",
      "34432/34479 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9629Epoch 00004: val_loss improved from 0.09737 to 0.09700, saving model to ../data/weights/conv_best.hk\n",
      "34479/34479 [==============================] - 189s - loss: 0.0944 - acc: 0.9630 - val_loss: 0.0970 - val_acc: 0.9616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd636f776d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '../data/weights/conv_best_smaller_LR_1.hk'\n",
    "vgg.model.compile(optimizer=Adam(lr=0.0001),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg.model.fit_generator(traingen, samples_per_epoch=traingen.nb_sample, nb_epoch=5,\n",
    "                        validation_data=valgen, nb_val_samples=valgen.nb_sample,\n",
    "                        callbacks=[history, saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "34351/34479 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9634Epoch 00000: val_loss improved from inf to 0.09612, saving model to ../data/weights/conv_best_smaller_LR_2.hk\n",
      "34479/34479 [==============================] - 184s - loss: 0.0930 - acc: 0.9634 - val_loss: 0.0961 - val_acc: 0.9619\n",
      "Epoch 2/5\n",
      "34351/34479 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9637Epoch 00001: val_loss did not improve\n",
      "34479/34479 [==============================] - 184s - loss: 0.0932 - acc: 0.9636 - val_loss: 0.0962 - val_acc: 0.9618\n",
      "Epoch 3/5\n",
      "34351/34479 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9637Epoch 00002: val_loss did not improve\n",
      "34479/34479 [==============================] - 184s - loss: 0.0927 - acc: 0.9637 - val_loss: 0.0962 - val_acc: 0.9618\n",
      "Epoch 4/5\n",
      "34351/34479 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9635Epoch 00003: val_loss did not improve\n",
      "34479/34479 [==============================] - 183s - loss: 0.0934 - acc: 0.9635 - val_loss: 0.0962 - val_acc: 0.9618\n",
      "Epoch 5/5\n",
      "34351/34479 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9634Epoch 00004: val_loss improved from 0.09612 to 0.09610, saving model to ../data/weights/conv_best_smaller_LR_2.hk\n",
      "34479/34479 [==============================] - 187s - loss: 0.0930 - acc: 0.9634 - val_loss: 0.0961 - val_acc: 0.9619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd64c1ed2d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '../data/weights/conv_best_smaller_LR_2.hk'\n",
    "saver = ModelCheckpoint(filepath, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "vgg.model.compile(optimizer=Adam(lr=0.00001),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg.model.fit_generator(traingen, samples_per_epoch=traingen.nb_sample, nb_epoch=5,\n",
    "                        validation_data=valgen, nb_val_samples=valgen.nb_sample,\n",
    "                        callbacks=[history, saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = '../data/weights/conv_best_smaller_LR_2.hk'\n",
    "vgg.model.load_weights(filepath)\n",
    "vgg.model.save_weights('../data/weights/atc_1.hk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.save_weights('../data/weights/conv_end.hk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = vgg.model.predict_generator(traingen, traingen.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01696215,  0.01674472,  0.0167875 , ...,  0.01675965,\n",
       "        0.01569044,  0.0170305 ], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 189.30000305,    3.24000001,    1.72000003,    2.29999995,\n",
       "          4.78000021,  463.79000854,   33.86999893,    1.        ,\n",
       "         80.68000031,   59.18999863,   25.10000038,   66.55000305,\n",
       "        559.72998047,  154.77999878,    1.03999996,    2.16000009,\n",
       "         89.87999725], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(preds[0]/min(preds[0]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [\n",
    "    \"agriculture\",\n",
    "    \"artisinal_mine\",\n",
    "    \"bare_ground\",\n",
    "    \"blooming\",\n",
    "    \"blow_down\",\n",
    "    \"clear\",\n",
    "    \"cloudy\",\n",
    "    \"conventional_mine\",\n",
    "    \"cultivation\",\n",
    "    \"habitation\",\n",
    "    \"haze\",\n",
    "    \"partly_cloudy\",\n",
    "    \"primary\",\n",
    "    \"road\",\n",
    "    \"selective_logging\",\n",
    "    \"slash_burn\",\n",
    "    \"water\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
